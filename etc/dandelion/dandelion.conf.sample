[DEFAULT]

#
# From oslo.log
#

# If set to true, the logging level will be set to DEBUG instead of the default INFO level (boolean
# value)
# Note: This option can be changed without restarting.
#debug = false

# The name of a logging configuration file. This file is appended to any existing logging
# configuration files. For details about logging configuration files, see the Python logging module
# documentation. Note that when logging configuration files are used then all logging configuration
# is set in the configuration file and other logging configuration options are ignored (for
# example, log-date-format) (string value)
# Note: This option can be changed without restarting.
# Deprecated group/name - [DEFAULT]/log_config
#log_config_append = <None>

# Defines the format string for %%(asctime)s in log records. Default: %(default)s . This option is
# ignored if log_config_append is set (string value)
#log_date_format = %Y-%m-%d %H:%M:%S

# (Optional) Name of log file to send logging output to. If no default is set, logging will go to
# stderr as defined by use_stderr. This option is ignored if log_config_append is set (string
# value)
# Deprecated group/name - [DEFAULT]/logfile
#log_file = <None>

# (Optional) The base directory used for relative log_file  paths. This option is ignored if
# log_config_append is set (string value)
# Deprecated group/name - [DEFAULT]/logdir
#log_dir = <None>

# Uses logging handler designed to watch file system. When log file is moved or removed this
# handler will open a new log file with specified path instantaneously. It makes sense only if
# log_file option is specified and Linux platform is used. This option is ignored if
# log_config_append is set (boolean value)
#watch_log_file = false

# Use syslog for logging. Existing syslog format is DEPRECATED and will be changed later to honor
# RFC5424. This option is ignored if log_config_append is set (boolean value)
#use_syslog = false

# Enable journald for logging. If running in a systemd environment you may wish to enable journal
# support. Doing so will use the journal native protocol which includes structured metadata in
# addition to log messages.This option is ignored if log_config_append is set (boolean value)
#use_journal = false

# Syslog facility to receive log lines. This option is ignored if log_config_append is set (string
# value)
#syslog_log_facility = LOG_USER

# Use JSON formatting for logging. This option is ignored if log_config_append is set (boolean
# value)
#use_json = false

# Log output to standard error. This option is ignored if log_config_append is set (boolean value)
#use_stderr = false

# Log output to Windows Event Log (boolean value)
#use_eventlog = false

# The amount of time before the log files are rotated. This option is ignored unless
# log_rotation_type is set to "interval" (integer value)
#log_rotate_interval = 1

# Rotation interval type. The time of the last file change (or the time when the service was
# started) is used when scheduling the next rotation (string value)
# Possible values:
# Seconds - <No description provided>
# Minutes - <No description provided>
# Hours - <No description provided>
# Days - <No description provided>
# Weekday - <No description provided>
# Midnight - <No description provided>
#log_rotate_interval_type = days

# Maximum number of rotated log files (integer value)
#max_logfile_count = 30

# Log file maximum size in MB. This option is ignored if "log_rotation_type" is not set to "size"
# (integer value)
#max_logfile_size_mb = 200

# Log rotation type (string value)
# Possible values:
# interval - Rotate logs at predefined time intervals.
# size - Rotate logs once they reach a predefined size.
# none - Do not rotate log files.
#log_rotation_type = none

# Format string to use for log messages with context. Used by oslo_log.formatters.ContextFormatter
# (string value)
#logging_context_format_string = %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [%(global_request_id)s %(request_id)s %(user_identity)s] %(instance)s%(message)s

# Format string to use for log messages when context is undefined. Used by
# oslo_log.formatters.ContextFormatter (string value)
#logging_default_format_string = %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s

# Additional data to append to log message when logging level for the message is DEBUG. Used by
# oslo_log.formatters.ContextFormatter (string value)
#logging_debug_format_suffix = %(funcName)s %(pathname)s:%(lineno)d

# Prefix each line of exception output with this format. Used by
# oslo_log.formatters.ContextFormatter (string value)
#logging_exception_prefix = %(asctime)s.%(msecs)03d %(process)d ERROR %(name)s %(instance)s

# Defines the format string for %(user_identity)s that is used in logging_context_format_string.
# Used by oslo_log.formatters.ContextFormatter (string value)
#logging_user_identity_format = %(user)s %(project)s %(domain)s %(system_scope)s %(user_domain)s %(project_domain)s

# List of package logging levels in logger=LEVEL pairs. This option is ignored if log_config_append
# is set (list value)
#default_log_levels = amqp=WARN,amqplib=WARN,boto=WARN,qpid=WARN,sqlalchemy=WARN,suds=INFO,oslo.messaging=INFO,oslo_messaging=INFO,iso8601=WARN,requests.packages.urllib3.connectionpool=WARN,urllib3.connectionpool=WARN,websocket=WARN,requests.packages.urllib3.util.retry=WARN,urllib3.util.retry=WARN,keystonemiddleware=WARN,routes.middleware=WARN,stevedore=WARN,taskflow=WARN,keystoneauth=WARN,oslo.cache=INFO,oslo_policy=INFO,dogpile.core.dogpile=INFO

# Enables or disables publication of error events (boolean value)
#publish_errors = false

# The format for an instance that is passed with the log message (string value)
#instance_format = "[instance: %(uuid)s] "

# The format for an instance UUID that is passed with the log message (string value)
#instance_uuid_format = "[instance: %(uuid)s] "

# Interval, number of seconds, of log rate limiting (integer value)
#rate_limit_interval = 0

# Maximum number of logged messages per rate_limit_interval (integer value)
#rate_limit_burst = 0

# Log level name used by rate limiting: CRITICAL, ERROR, INFO, WARNING, DEBUG or empty string. Logs
# with level greater or equal to rate_limit_except_level are not filtered. An empty string means
# that all levels are filtered (string value)
#rate_limit_except_level = CRITICAL

# Enables or disables fatal status of deprecations (boolean value)
#fatal_deprecations = false


[cors]
#
# CORS related options.

#
# From dandelion.conf
#

#
# CORS origins.
#  (list value)
#origins =


[database]
#
# Database related options.

#
# From dandelion.conf
#

#
# Connection of database.
#  (string value)
#connection = sqlite:////tmp/dandelion.db

#
# Maximum number of SQL connections to keep open in a pool.
# Setting a value of 0 indicates no limit.
#  (integer value)
#max_pool_size = 50

#
# If set, use this value for max_overflow with sqlalchemy.
#  (integer value)
#max_overflow = 1000


[iam]
#
# iam related options.

#
# From dandelion.conf
#

#
# iam get_auth_info_url.
#  (string value)
#get_auth_info_url = http://203.166.165.251:16056/?Action=GetAuthInfo


[mode]
#
# Mode related options.

#
# From dandelion.conf
#

#
# Mode. Default: coexist
# Possible values:
# edge - The edge node sends data to the cloud control center
# center - The cloud control center displays the data reported by the connected edge nodes
# coexist - Coexistence of cloud control center and edge nodes
#  (string value)
#mode = coexist


[mqtt]
#
# MQTT related options.

#
# From dandelion.conf
#

#
# Host of MQTT server.
#  (IP address value)
#host = <None>

#
# Port of MQTT server.
#  (port value)
# Minimum value: 0
# Maximum value: 65535
#port = 1883

#
# Username of MQTT server.
#  (string value)
#username = <None>

#
# Password for username of MQTT server.
#  (string value)
#password = <None>


[redis]
#
# Redis related options.

#
# From dandelion.conf
#

#
# Connection of redis.
# If you have a single redis server, you can set connection as followed:
# "redis://<user>:<password>@<ip>:<port>?db=0&socket_timeout=60&retry_on_timeout=yes".
# If you have a sentinel redis cluster, you can set connection as followed:
# "redis://<user>:<password>@<ip>:<port>?sentinel=<sentinel>&sentinel_fallback=<ip>:<port>&sentinel_fallback=<ip>:<port>&db=0&socket_timeout=60&retry_on_timeout=yes"
#  (string value)
#connection = <None>


[token]
#
# Token related options.

#
# From dandelion.conf
#

#
# Token expire seonds. Default: 604800(7 days).
#  (integer value)
#expire_seconds = 604800

#
# Secret key of token.
#  (string value)
#secret_key = CP7l45i1SEk7jues8DAcO3MnWe-NMKITz3XrMxHBZhY


[user]
#
# user related options.

#
# From dandelion.conf
#

#
# username.
#  (string value)
#username = admin

#
# user password.
#  (string value)
#password = dandelion
